{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SypF2Xj6OvmD"
      },
      "source": [
        "# Installing Java 8\n",
        "Hadoop is a java programming-based data processing framework\n",
        "\n",
        "OpenJDK is a development environment for building applications, applets, and components using the Java programming language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqfPfV3BIxlK",
        "outputId": "d2b17667-4c80-4e98-bb0e-fa80fc33d81c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.26\" 2025-01-21\n",
            "OpenJDK Runtime Environment (build 11.0.26+4-post-Ubuntu-1ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.26+4-post-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in manual mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in manual mode\n",
            "openjdk version \"1.8.0_442\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_442-8u442-b06~us1-0ubuntu1~22.04-b06)\n",
            "OpenJDK 64-Bit Server VM (build 25.442-b06, mixed mode)\n",
            "/usr/lib/jvm/java-8-openjdk-amd64/jre/\n",
            " * Starting OpenBSD Secure Shell server sshd\n",
            "   ...done.\n",
            "#Port 22\n",
            "#GatewayPorts no\n",
            "Generating public/private rsa key pair.\n",
            "Created directory '/root/.ssh'.\n",
            "Your identification has been saved in /root/.ssh/id_rsa\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub\n",
            "The key fingerprint is:\n",
            "SHA256:StUYs7/lrxcczQ00PxBpHv1u+xbCUPfu4usD3ODP7QQ root@d5cdf3b79686\n",
            "The key's randomart image is:\n",
            "+---[RSA 3072]----+\n",
            "|        o    +*  |\n",
            "|         *   =o= |\n",
            "|        + . + o==|\n",
            "|       . . .... B|\n",
            "|      . S .o++E+ |\n",
            "|     . .   ++o+o+|\n",
            "|      .   . .+.=+|\n",
            "|             .*o+|\n",
            "|            .==*+|\n",
            "+----[SHA256]-----+\n",
            "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDUCZOabI4CEO/rh1T63FwdG8f20RoUV9/8YGrX+H9uIoXeynFMRCadkOe0HCd6\n",
            "RzKwpSZH7eVPa0Fbtzx7xY3byZd4+uWFUS2ibR8ueE3pfC8vyeWA/wDOkJRosrrDKp5JTavCJmkW7KnEVq1oWAnaHWRXqIrxVCqH\n",
            "cvYZtlsB0YLREJrevAjmWs7SCtom42J61bvWGHR7SDk0BRHdW5ZCn8DScemtsjVVcC+0q08E9wo4o5BgQP/wuozF7X4BTnsBKI74\n",
            "bhYHoSuItM/Gx/J221zF5cirYlWqws4axHnbDRizvwTxd6+OHxlIYmbFHT35KqANJVeFdszyHjkfKUvnGVaNvTUPVHQ2EsdcRwA2\n",
            "HdainBUAxO+9H/JksQHjHTmgxhv+lV8voXWTlpbJng5SWfCN2d66WU/2LRWVdLdw+lTewe9DElh6HvhFUyv/Ml2DicYlsjTfJwoC\n",
            "jYyzRAq82fOwD6Xx2qG3RX9YBQyM16Y4nzwemtjgZWhiOINRFTk= root@d5cdf3b79686\n",
            "Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
            " 17:02:34 up 3 min,  0 users,  load average: 2.41, 1.33, 0.54\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!java -version\n",
        "\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!update-alternatives --set javac /usr/lib/jvm/java-8-openjdk-amd64/bin/javac\n",
        "!update-alternatives --set jps /usr/lib/jvm/java-8-openjdk-amd64/bin/jps\n",
        "!java -version\n",
        "\n",
        "#Finding the default Java path\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "!apt-get install openssh-server -qq > /dev/null\n",
        "!service ssh start\n",
        "\n",
        "!grep Port /etc/ssh/sshd_config\n",
        "\n",
        "#Creating a new rsa key pair with empty password\n",
        "!ssh-keygen -t rsa -P \"\" -f ~/.ssh/id_rsa <<< y\n",
        "\n",
        "# See id_rsa.pub content\n",
        "!more /root/.ssh/id_rsa.pub\n",
        "\n",
        "#Copying the key to autorized keys\n",
        "!cat $HOME/.ssh/id_rsa.pub > $HOME/.ssh/authorized_keys\n",
        "#Changing the permissions on the key\n",
        "!chmod 0600 ~/.ssh/authorized_keys\n",
        "\n",
        "#Conneting with the local machine\n",
        "!ssh -o StrictHostKeyChecking=no localhost uptime\n",
        "\n",
        "# https://archive.apache.org/dist/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz\n",
        "# mirror download: http://mirrors.cloud.aliyuncs.com/apache/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz\n",
        "\n",
        "#Downloading Hadoop 3.2.4\n",
        "!wget -q https://downloads.apache.org/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz\n",
        "\n",
        "#Untarring the file\n",
        "!sudo tar -xzf hadoop-3.2.4.tar.gz\n",
        "#Removing the tar file\n",
        "!rm hadoop-3.2.4.tar.gz\n",
        "\n",
        "\n",
        "#Copying the hadoop files to user/local\n",
        "!cp -r hadoop-3.2.4/ /usr/local/\n",
        "#-r copy directories recursively\n",
        "\n",
        "#Adding JAVA_HOME directory to hadoop-env.sh file\n",
        "!sed -i '/export JAVA_HOME=/a export JAVA_HOME=\\/usr\\/lib\\/jvm\\/java-8-openjdk-amd64' /usr/local/hadoop-3.2.4/etc/hadoop/hadoop-env.sh\n",
        "\n",
        "import os\n",
        "#Creating environment variables\n",
        "#Creating Hadoop home variable\n",
        "\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.2.4\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\"\n",
        "os.environ[\"PATH\"] += f'{os.environ[\"JAVA_HOME\"]}/bin:{os.environ[\"JRE_HOME\"]}/bin:{os.environ[\"HADOOP_HOME\"]}/sbin'\n",
        "\n",
        "#Dowloading text example to use as input\n",
        "!wget -q https://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/101/101.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qK_Ozh8RVza-"
      },
      "outputs": [],
      "source": [
        "#Adding required property to core-site.xml file\n",
        "%%bash\n",
        "cat <<EOF > $HADOOP_HOME/etc/hadoop/core-site.xml\n",
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
        "<!--\n",
        "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "  you may not use this file except in compliance with the License.\n",
        "  You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "  Unless required by applicable law or agreed to in writing, software\n",
        "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "  See the License for the specific language governing permissions and\n",
        "  limitations under the License. See accompanying LICENSE file.\n",
        "-->\n",
        "\n",
        "<!-- Put site-specific property overrides in this file. -->\n",
        "\n",
        "<configuration>\n",
        "  <property>\n",
        "          <name>fs.defaultFS</name>\n",
        "          <value>hdfs://localhost:9000</value>\n",
        "          <description>Where HDFS NameNode can be found on the network</description>\n",
        "  </property>\n",
        "</configuration>\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iRlijZzZ5_IQ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat <<EOF > $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n",
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
        "<!--\n",
        "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "  you may not use this file except in compliance with the License.\n",
        "  You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "  Unless required by applicable law or agreed to in writing, software\n",
        "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "  See the License for the specific language governing permissions and\n",
        "  limitations under the License. See accompanying LICENSE file.\n",
        "-->\n",
        "\n",
        "<!-- Put site-specific property overrides in this file. -->\n",
        "\n",
        "<configuration>\n",
        "<property>\n",
        "    <name>dfs.replication</name>\n",
        "    <value>1</value>\n",
        "  </property>\n",
        "\n",
        "</configuration>\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oI7EXvcy8x5Q"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat <<EOF > $HADOOP_HOME/etc/hadoop/mapred-site.xml\n",
        "<?xml version=\"1.0\"?>\n",
        "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
        "<!--\n",
        "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "  you may not use this file except in compliance with the License.\n",
        "  You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "  Unless required by applicable law or agreed to in writing, software\n",
        "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "  See the License for the specific language governing permissions and\n",
        "  limitations under the License. See accompanying LICENSE file.\n",
        "-->\n",
        "\n",
        "<!-- Put site-specific property overrides in this file. -->\n",
        "\n",
        "<configuration>\n",
        "<property>\n",
        "    <name>mapreduce.framework.name</name>\n",
        "    <value>yarn</value>\n",
        "  </property>\n",
        "  <property>\n",
        "    <name>mapreduce.application.classpath</name>\n",
        "    <value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*</value>\n",
        "  </property>\n",
        "\n",
        "</configuration>\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VXqsVh1M9Pxu"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat <<EOF > $HADOOP_HOME/etc/hadoop/yarn-site.xml\n",
        "<?xml version=\"1.0\"?>\n",
        "<!--\n",
        "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "  you may not use this file except in compliance with the License.\n",
        "  You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "  Unless required by applicable law or agreed to in writing, software\n",
        "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "  See the License for the specific language governing permissions and\n",
        "  limitations under the License. See accompanying LICENSE file.\n",
        "-->\n",
        "<configuration>\n",
        "<property>\n",
        "    <description>The hostname of the RM.</description>\n",
        "    <name>yarn.resourcemanager.hostname</name>\n",
        "    <value>localhost</value>\n",
        "  </property>\n",
        "  <property>\n",
        "    <name>yarn.nodemanager.aux-services</name>\n",
        "    <value>mapreduce_shuffle</value>\n",
        "  </property>\n",
        "  <property>\n",
        "    <name>yarn.nodemanager.env-whitelist</name>\n",
        "    <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>\n",
        "  </property>\n",
        "\n",
        "<!-- Site specific YARN configuration properties -->\n",
        "\n",
        "</configuration>\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat $HADOOP_HOME/etc/hadoop/core-site.xml"
      ],
      "metadata": {
        "id": "4461KHi8yIHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434f9f4d-4e69-4c25-fb2c-0756ce865cc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
            "<!--\n",
            "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "  you may not use this file except in compliance with the License.\n",
            "  You may obtain a copy of the License at\n",
            "\n",
            "    http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "  Unless required by applicable law or agreed to in writing, software\n",
            "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "  See the License for the specific language governing permissions and\n",
            "  limitations under the License. See accompanying LICENSE file.\n",
            "-->\n",
            "\n",
            "<!-- Put site-specific property overrides in this file. -->\n",
            "\n",
            "<configuration>\n",
            "  <property>\n",
            "          <name>fs.defaultFS</name>\n",
            "          <value>hdfs://localhost:9000</value>\n",
            "          <description>Where HDFS NameNode can be found on the network</description>\n",
            "  </property>\n",
            "</configuration>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeDr2ydyXYFK"
      },
      "source": [
        "# Formatting the HDFS Filesystem\n",
        "\n",
        "Before HDFS can be used for the first time the file system must be formatted. The formatting process creates an empty file system by creating the storage directories and the initial versions of the NameNodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vmrjTfnQ9rzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f069f5ad-a6a7-46b6-dd1d-9bc9fcd1ec7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: /usr/local/hadoop-3.2.4/logs does not exist. Creating.\n",
            "2025-03-13 17:03:25,608 INFO namenode.NameNode: STARTUP_MSG: \n",
            "/************************************************************\n",
            "STARTUP_MSG: Starting NameNode\n",
            "STARTUP_MSG:   host = d5cdf3b79686/172.28.0.12\n",
            "STARTUP_MSG:   args = [-format]\n",
            "STARTUP_MSG:   version = 3.2.4\n",
            "STARTUP_MSG:   classpath = /usr/local/hadoop-3.2.4/etc/hadoop:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-compress-1.21.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-io-2.8.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/httpcore-4.4.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/zookeeper-3.4.14.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/hadoop-annotations-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/stax2-api-4.2.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/hadoop-auth-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/gson-2.9.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/slf4j-api-1.7.35.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/json-smart-2.4.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/netty-3.10.6.Final.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-core-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/slf4j-reload4j-1.7.35.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jsch-0.1.55.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jsr305-3.0.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jul-to-slf4j-1.7.35.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/httpclient-4.5.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/hadoop-nfs-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/hadoop-kms-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/hadoop-common-3.2.4-tests.jar:/usr/local/hadoop-3.2.4/share/hadoop/common/hadoop-common-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/zookeeper-3.4.14.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/netty-all-4.1.68.Final.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/hadoop-annotations-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/hadoop-auth-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/gson-2.9.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/spotbugs-annotations-3.1.9.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-client-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.4-tests.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-client-3.2.4-tests.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-3.2.4-tests.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.4-tests.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.4-tests.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-api-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-registry-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-client-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-services-core-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-submarine-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-common-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-server-router-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-common-3.2.4.jar:/usr/local/hadoop-3.2.4/share/hadoop/yarn/hadoop-yarn-services-api-3.2.4.jar\n",
            "STARTUP_MSG:   build = Unknown -r 7e5d9983b388e372fe640f21f048f2f2ae6e9eba; compiled by 'ubuntu' on 2022-07-12T11:58Z\n",
            "STARTUP_MSG:   java = 1.8.0_442\n",
            "************************************************************/\n",
            "2025-03-13 17:03:25,718 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
            "2025-03-13 17:03:25,860 INFO namenode.NameNode: createNameNode [-format]\n",
            "Formatting using clusterid: CID-0a330c17-9b49-4a84-b464-41ea2dfa6662\n",
            "2025-03-13 17:03:26,697 INFO namenode.FSEditLog: Edit logging is async:true\n",
            "2025-03-13 17:03:26,741 INFO namenode.FSNamesystem: KeyProvider: null\n",
            "2025-03-13 17:03:26,743 INFO namenode.FSNamesystem: fsLock is fair: true\n",
            "2025-03-13 17:03:26,745 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
            "2025-03-13 17:03:26,755 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\n",
            "2025-03-13 17:03:26,755 INFO namenode.FSNamesystem: supergroup          = supergroup\n",
            "2025-03-13 17:03:26,755 INFO namenode.FSNamesystem: isPermissionEnabled = true\n",
            "2025-03-13 17:03:26,756 INFO namenode.FSNamesystem: HA Enabled: false\n",
            "2025-03-13 17:03:26,828 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
            "2025-03-13 17:03:26,842 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\n",
            "2025-03-13 17:03:26,842 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
            "2025-03-13 17:03:26,870 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
            "2025-03-13 17:03:26,871 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Mar 13 17:03:26\n",
            "2025-03-13 17:03:26,874 INFO util.GSet: Computing capacity for map BlocksMap\n",
            "2025-03-13 17:03:26,874 INFO util.GSet: VM type       = 64-bit\n",
            "2025-03-13 17:03:26,876 INFO util.GSet: 2.0% max memory 2.8 GB = 57.7 MB\n",
            "2025-03-13 17:03:26,877 INFO util.GSet: capacity      = 2^23 = 8388608 entries\n",
            "2025-03-13 17:03:26,895 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\n",
            "2025-03-13 17:03:26,895 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\n",
            "2025-03-13 17:03:26,903 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n",
            "2025-03-13 17:03:26,903 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
            "2025-03-13 17:03:26,903 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
            "2025-03-13 17:03:26,904 INFO blockmanagement.BlockManager: defaultReplication         = 1\n",
            "2025-03-13 17:03:26,904 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
            "2025-03-13 17:03:26,904 INFO blockmanagement.BlockManager: minReplication             = 1\n",
            "2025-03-13 17:03:26,904 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
            "2025-03-13 17:03:26,904 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\n",
            "2025-03-13 17:03:26,905 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
            "2025-03-13 17:03:26,905 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
            "2025-03-13 17:03:26,936 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\n",
            "2025-03-13 17:03:26,936 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\n",
            "2025-03-13 17:03:26,936 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\n",
            "2025-03-13 17:03:26,936 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\n",
            "2025-03-13 17:03:26,960 INFO util.GSet: Computing capacity for map INodeMap\n",
            "2025-03-13 17:03:26,960 INFO util.GSet: VM type       = 64-bit\n",
            "2025-03-13 17:03:26,960 INFO util.GSet: 1.0% max memory 2.8 GB = 28.9 MB\n",
            "2025-03-13 17:03:26,960 INFO util.GSet: capacity      = 2^22 = 4194304 entries\n",
            "2025-03-13 17:03:27,062 INFO namenode.FSDirectory: ACLs enabled? false\n",
            "2025-03-13 17:03:27,062 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\n",
            "2025-03-13 17:03:27,062 INFO namenode.FSDirectory: XAttrs enabled? true\n",
            "2025-03-13 17:03:27,063 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
            "2025-03-13 17:03:27,070 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\n",
            "2025-03-13 17:03:27,073 INFO snapshot.SnapshotManager: SkipList is disabled\n",
            "2025-03-13 17:03:27,080 INFO util.GSet: Computing capacity for map cachedBlocks\n",
            "2025-03-13 17:03:27,080 INFO util.GSet: VM type       = 64-bit\n",
            "2025-03-13 17:03:27,080 INFO util.GSet: 0.25% max memory 2.8 GB = 7.2 MB\n",
            "2025-03-13 17:03:27,080 INFO util.GSet: capacity      = 2^20 = 1048576 entries\n",
            "2025-03-13 17:03:27,091 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
            "2025-03-13 17:03:27,091 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
            "2025-03-13 17:03:27,091 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
            "2025-03-13 17:03:27,097 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
            "2025-03-13 17:03:27,097 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
            "2025-03-13 17:03:27,099 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
            "2025-03-13 17:03:27,099 INFO util.GSet: VM type       = 64-bit\n",
            "2025-03-13 17:03:27,100 INFO util.GSet: 0.029999999329447746% max memory 2.8 GB = 886.4 KB\n",
            "2025-03-13 17:03:27,100 INFO util.GSet: capacity      = 2^17 = 131072 entries\n",
            "2025-03-13 17:03:27,141 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1296714706-172.28.0.12-1741885407125\n",
            "2025-03-13 17:03:27,217 INFO common.Storage: Storage directory /tmp/hadoop-root/dfs/name has been successfully formatted.\n",
            "2025-03-13 17:03:27,263 INFO namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-root/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression\n",
            "2025-03-13 17:03:27,398 INFO namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-root/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\n",
            "2025-03-13 17:03:27,421 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
            "2025-03-13 17:03:27,512 INFO namenode.FSNamesystem: Stopping services started for active state\n",
            "2025-03-13 17:03:27,513 INFO namenode.FSNamesystem: Stopping services started for standby state\n",
            "2025-03-13 17:03:27,519 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\n",
            "2025-03-13 17:03:27,520 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
            "/************************************************************\n",
            "SHUTDOWN_MSG: Shutting down NameNode at d5cdf3b79686/172.28.0.12\n",
            "************************************************************/\n",
            "Starting namenodes on [localhost]\n",
            "Starting datanodes\n",
            "Starting secondary namenodes [d5cdf3b79686]\n",
            "d5cdf3b79686: Warning: Permanently added 'd5cdf3b79686' (ED25519) to the list of known hosts.\n",
            "nohup: ignoring input and appending output to 'nohup.out'\n",
            "1586 NameNode\n",
            "2258 NodeManager\n",
            "1890 SecondaryNameNode\n",
            "1698 DataNode\n",
            "2147 ResourceManager\n",
            "2372 Jps\n"
          ]
        }
      ],
      "source": [
        "!$HADOOP_HOME/bin/hdfs namenode -format\n",
        "\n",
        "#Creating other necessary enviroment variables before starting nodes\n",
        "os.environ[\"HDFS_NAMENODE_USER\"] = \"root\"\n",
        "os.environ[\"HDFS_DATANODE_USER\"] = \"root\"\n",
        "os.environ[\"HDFS_SECONDARYNAMENODE_USER\"] = \"root\"\n",
        "os.environ[\"YARN_RESOURCEMANAGER_USER\"] = \"root\"\n",
        "os.environ[\"YARN_NODEMANAGER_USER\"] = \"root\"\n",
        "\n",
        "#Launching hdfs deamons\n",
        "!$HADOOP_HOME/sbin/start-dfs.sh\n",
        "\n",
        "#Launching yarn deamons\n",
        "#nohup causes a process to ignore a SIGHUP signal\n",
        "!nohup $HADOOP_HOME/sbin/start-yarn.sh\n",
        "\n",
        "#Listing the running deamons\n",
        "!jps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srV27xSGXu5O"
      },
      "source": [
        "### Monitoring Hadoop cluster with hadoop admin commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zUxnt00v_wqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960ad6ce-921b-4e3b-fa54-6cb78cda13ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured Capacity: 115658190848 (107.72 GB)\n",
            "Present Capacity: 73758453760 (68.69 GB)\n",
            "DFS Remaining: 73758429184 (68.69 GB)\n",
            "DFS Used: 24576 (24 KB)\n",
            "DFS Used%: 0.00%\n",
            "Replicated Blocks:\n",
            "\tUnder replicated blocks: 0\n",
            "\tBlocks with corrupt replicas: 0\n",
            "\tMissing blocks: 0\n",
            "\tMissing blocks (with replication factor 1): 0\n",
            "\tLow redundancy blocks with highest priority to recover: 0\n",
            "\tPending deletion blocks: 0\n",
            "Erasure Coded Block Groups: \n",
            "\tLow redundancy block groups: 0\n",
            "\tBlock groups with corrupt internal blocks: 0\n",
            "\tMissing block groups: 0\n",
            "\tLow redundancy blocks with highest priority to recover: 0\n",
            "\tPending deletion blocks: 0\n",
            "\n",
            "-------------------------------------------------\n",
            "Live datanodes (1):\n",
            "\n",
            "Name: 127.0.0.1:9866 (localhost)\n",
            "Hostname: d5cdf3b79686\n",
            "Decommission Status : Normal\n",
            "Configured Capacity: 115658190848 (107.72 GB)\n",
            "DFS Used: 24576 (24 KB)\n",
            "Non DFS Used: 41882959872 (39.01 GB)\n",
            "DFS Remaining: 73758429184 (68.69 GB)\n",
            "DFS Used%: 0.00%\n",
            "DFS Remaining%: 63.77%\n",
            "Configured Cache Capacity: 0 (0 B)\n",
            "Cache Used: 0 (0 B)\n",
            "Cache Remaining: 0 (0 B)\n",
            "Cache Used%: 100.00%\n",
            "Cache Remaining%: 0.00%\n",
            "Xceivers: 1\n",
            "Last contact: Thu Mar 13 17:04:05 UTC 2025\n",
            "Last Block Report: Thu Mar 13 17:03:44 UTC 2025\n",
            "Num of Blocks: 0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Report the basic file system information and statistics\n",
        "!$HADOOP_HOME/bin/hdfs dfsadmin -report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkINc9skYBld"
      },
      "source": [
        "# MapReduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-VjzSc7jRrOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ae4ba1-21e9-4747-997f-15710a36d88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 items\n",
            "-rw-r--r--   1 root supergroup       1412 2025-03-13 17:04 /word_count/wordcount.txt\n"
          ]
        }
      ],
      "source": [
        "#Dowloading text example to use as input (if it has not been donwloaded yet)\n",
        "!wget -q https://raw.githubusercontent.com/ayyoubmaul/hadoop-docker/refs/heads/main/data/uud45.txt -O wordcount.txt\n",
        "\n",
        "# Create a directory in HDFS and upload the file\n",
        "!$HADOOP_HOME/bin/hdfs dfs -mkdir /word_count\n",
        "!$HADOOP_HOME/bin/hdfs dfs -put /content/wordcount.txt /word_count\n",
        "\n",
        "#Exploring Hadoop folder\n",
        "!$HADOOP_HOME/bin/hdfs dfs -ls /word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k6_U5EszSUy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8295b874-9bba-4a64-bee9-a6eb877db680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: `/word_count/output_wordcount': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#Exploring the created output directory\n",
        "#part-r-00000 contains the actual ouput\n",
        "!$HADOOP_HOME/bin/hdfs dfs -ls /word_count/output_wordcount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cq8XtDRTBHD"
      },
      "source": [
        "# Mapper and Reducer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k_Dk8vLYTDqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7770baf5-a0a3-4227-dfdd-145b3fbbba33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mapper.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mapper.py\n",
        "#!/usr/bin/env python\n",
        "import sys\n",
        "\n",
        "for line in sys.stdin:\n",
        "    line = line.strip()\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        print('%s\\t%s' % (word, 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reducer.py\n",
        "#!/usr/bin/env python\n",
        "import sys\n",
        "\n",
        "current_word = None\n",
        "current_count = 0\n",
        "word = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "    line = line.strip()\n",
        "    word, count = line.split('\\t', 1)\n",
        "    try:\n",
        "        count = int(count)\n",
        "    except ValueError:\n",
        "        continue\n",
        "\n",
        "    if current_word == word:\n",
        "        current_count += count\n",
        "    else:\n",
        "        if current_word:\n",
        "            print('%s\\t%s' % (current_word, current_count))\n",
        "        current_count = count\n",
        "        current_word = word\n",
        "\n",
        "if current_word == word:\n",
        "    print('%s\\t%s' % (current_word, current_count))"
      ],
      "metadata": {
        "id": "uSYt9hCzPPxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac35f5a4-4d7a-4f7c-c652-be9e221bb553"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reducer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/mapper.py\n",
        "!chmod +x /content/reducer.py"
      ],
      "metadata": {
        "id": "KOfhhyOrO9fz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the MapReduce job\n",
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \\\n",
        "  -input /word_count/wordcount.txt \\\n",
        "  -output /word_count/output \\\n",
        "  -mapper \"python /content/mapper.py\" \\\n",
        "  -reducer \"python /content/reducer.py\""
      ],
      "metadata": {
        "id": "o6JGJpGtJ5KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f564672f-84c8-4787-e8e9-84fd59c8d1a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "packageJobJar: [/tmp/hadoop-unjar7922688624283937706/] [] /tmp/streamjob2485452831778438858.jar tmpDir=null\n",
            "2025-03-13 17:04:22,681 INFO client.RMProxy: Connecting to ResourceManager at localhost/127.0.0.1:8032\n",
            "2025-03-13 17:04:23,074 INFO client.RMProxy: Connecting to ResourceManager at localhost/127.0.0.1:8032\n",
            "2025-03-13 17:04:23,511 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1741885439730_0001\n",
            "2025-03-13 17:04:23,979 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2025-03-13 17:04:24,132 INFO mapreduce.JobSubmitter: number of splits:2\n",
            "2025-03-13 17:04:24,880 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1741885439730_0001\n",
            "2025-03-13 17:04:24,882 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2025-03-13 17:04:25,192 INFO conf.Configuration: resource-types.xml not found\n",
            "2025-03-13 17:04:25,193 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
            "2025-03-13 17:04:25,660 INFO impl.YarnClientImpl: Submitted application application_1741885439730_0001\n",
            "2025-03-13 17:04:25,786 INFO mapreduce.Job: The url to track the job: http://d5cdf3b79686:8088/proxy/application_1741885439730_0001/\n",
            "2025-03-13 17:04:25,789 INFO mapreduce.Job: Running job: job_1741885439730_0001\n",
            "2025-03-13 17:04:39,117 INFO mapreduce.Job: Job job_1741885439730_0001 running in uber mode : false\n",
            "2025-03-13 17:04:39,119 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2025-03-13 17:04:49,291 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2025-03-13 17:04:56,380 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2025-03-13 17:04:56,394 INFO mapreduce.Job: Job job_1741885439730_0001 completed successfully\n",
            "2025-03-13 17:04:56,520 INFO mapreduce.Job: Counters: 55\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=2131\n",
            "\t\tFILE: Number of bytes written=723982\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\t\tHDFS: Number of bytes read=2314\n",
            "\t\tHDFS: Number of bytes written=1276\n",
            "\t\tHDFS: Number of read operations=11\n",
            "\t\tHDFS: Number of large read operations=0\n",
            "\t\tHDFS: Number of write operations=2\n",
            "\t\tHDFS: Number of bytes read erasure-coded=0\n",
            "\tJob Counters \n",
            "\t\tKilled map tasks=1\n",
            "\t\tLaunched map tasks=2\n",
            "\t\tLaunched reduce tasks=1\n",
            "\t\tData-local map tasks=2\n",
            "\t\tTotal time spent by all maps in occupied slots (ms)=16496\n",
            "\t\tTotal time spent by all reduces in occupied slots (ms)=4230\n",
            "\t\tTotal time spent by all map tasks (ms)=16496\n",
            "\t\tTotal time spent by all reduce tasks (ms)=4230\n",
            "\t\tTotal vcore-milliseconds taken by all map tasks=16496\n",
            "\t\tTotal vcore-milliseconds taken by all reduce tasks=4230\n",
            "\t\tTotal megabyte-milliseconds taken by all map tasks=16891904\n",
            "\t\tTotal megabyte-milliseconds taken by all reduce tasks=4331520\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4\n",
            "\t\tMap output records=178\n",
            "\t\tMap output bytes=1769\n",
            "\t\tMap output materialized bytes=2137\n",
            "\t\tInput split bytes=196\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=120\n",
            "\t\tReduce shuffle bytes=2137\n",
            "\t\tReduce input records=178\n",
            "\t\tReduce output records=120\n",
            "\t\tSpilled Records=356\n",
            "\t\tShuffled Maps =2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=2\n",
            "\t\tGC time elapsed (ms)=546\n",
            "\t\tCPU time spent (ms)=2910\n",
            "\t\tPhysical memory (bytes) snapshot=856915968\n",
            "\t\tVirtual memory (bytes) snapshot=7616741376\n",
            "\t\tTotal committed heap usage (bytes)=871366656\n",
            "\t\tPeak Map Physical memory (bytes)=318521344\n",
            "\t\tPeak Map Virtual memory (bytes)=2537418752\n",
            "\t\tPeak Reduce Physical memory (bytes)=219885568\n",
            "\t\tPeak Reduce Virtual memory (bytes)=2542604288\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=2118\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1276\n",
            "2025-03-13 17:04:56,520 INFO streaming.StreamJob: Output directory: /word_count/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy output from HDFS to local\n",
        "!$HADOOP_HOME/bin/hdfs dfs -copyToLocal /word_count/output/part-00000 /content/output_word_count.txt\n",
        "\n",
        "# View the output\n",
        "!cat /content/output_word_count.txt"
      ],
      "metadata": {
        "id": "_fQKvbyjJ58F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81074bb-467f-470c-a81d-dec52363b054"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":\t1\n",
            "Allah\t1\n",
            "Atas\t1\n",
            "Bahwa\t1\n",
            "Dan\t1\n",
            "Dasar\t1\n",
            "Esa,\t1\n",
            "Indonesia\t8\n",
            "Indonesia,\t3\n",
            "Indonesia.\t1\n",
            "Kebangsaan\t1\n",
            "Kemerdekaan\t1\n",
            "Kemudian\t1\n",
            "Ketuhanan\t1\n",
            "Kuasa\t1\n",
            "Maha\t2\n",
            "Negara\t3\n",
            "Pemerintah\t1\n",
            "Republik\t1\n",
            "Undang-Undang\t1\n",
            "Yang\t2\n",
            "abadi\t1\n",
            "adil\t2\n",
            "bagi\t1\n",
            "bangsa\t2\n",
            "bangsa,\t1\n",
            "bebas,\t1\n",
            "beradab,\t1\n",
            "berbahagia\t1\n",
            "berdasar\t1\n",
            "berdasarkan\t1\n",
            "berdaulat,\t1\n",
            "berkat\t1\n",
            "berkedaulatan\t1\n",
            "berkehidupan\t1\n",
            "bersatu,\t1\n",
            "dalam\t3\n",
            "dan\t10\n",
            "darah\t1\n",
            "daripada\t1\n",
            "dengan\t6\n",
            "depan\t1\n",
            "diatas\t1\n",
            "didorongkan\t1\n",
            "dihapuskan,\t1\n",
            "dipimpin\t1\n",
            "disusunlah\t1\n",
            "dunia\t2\n",
            "gerbang\t1\n",
            "hak\t1\n",
            "harus\t1\n",
            "hikmat\t1\n",
            "ialah\t1\n",
            "ikut\t1\n",
            "ini\t1\n",
            "itu\t3\n",
            "itu,\t1\n",
            "karena\t1\n",
            "ke\t1\n",
            "keadilan\t2\n",
            "kebangsaan\t1\n",
            "kebijaksanaan\t1\n",
            "kehidupan\t1\n",
            "keinginan\t1\n",
            "kemanusiaan\t1\n",
            "kemerdekaan\t3\n",
            "kemerdekaan,\t1\n",
            "kemerdekaannya.\t1\n",
            "kepada\t2\n",
            "kerakyatan\t1\n",
            "kesejahteraan\t1\n",
            "ketertiban\t1\n",
            "luhur,\t1\n",
            "maka\t3\n",
            "makmur.\t1\n",
            "melaksanakan\t1\n",
            "melindungi\t1\n",
            "memajukan\t1\n",
            "membentuk\t1\n",
            "mencerdaskan\t1\n",
            "mengantarkan\t1\n",
            "menyatakan\t1\n",
            "merdeka,\t1\n",
            "mewujudkan\t1\n",
            "negara\t1\n",
            "oleh\t3\n",
            "penjajahan\t1\n",
            "perdamaian\t1\n",
            "pergerakan\t1\n",
            "perikeadilan.\t1\n",
            "perikemanusiaan\t1\n",
            "perjuangan\t1\n",
            "permusyawaratan/perwakilan,\t1\n",
            "persatuan\t1\n",
            "pintu\t1\n",
            "rahmat\t1\n",
            "rakyat\t4\n",
            "saat\t1\n",
            "sampailah\t1\n",
            "sebab\t1\n",
            "segala\t1\n",
            "segenap\t1\n",
            "selamat\t1\n",
            "seluruh\t2\n",
            "sentosa\t1\n",
            "serta\t1\n",
            "sesuai\t1\n",
            "sesungguhnya\t1\n",
            "sosial\t1\n",
            "sosial,\t1\n",
            "suatu\t4\n",
            "supaya\t1\n",
            "susunan\t1\n",
            "telah\t1\n",
            "terbentuk\t1\n",
            "tidak\t1\n",
            "tumpah\t1\n",
            "umum,\t1\n",
            "untuk\t2\n",
            "yang\t9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGOD5hgzZboV"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}